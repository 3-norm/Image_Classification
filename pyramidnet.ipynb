{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import wandb\n",
    "import random\n",
    "import math\n",
    "\n",
    "import tarfile\n",
    "import pickle\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm"
   ]
  },
 {
   "cell_type": "markdown",
   "id": "86e8607c-d329-48de-aaca-6243dc98b401",
   "metadata": {},
   "source": [
    "#### Seed setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seed(327)"
   ]
  },
 {
   "cell_type": "markdown",
   "id": "86e8607c-d329-48de-aaca-6243dc98b401",
   "metadata": {},
   "source": [
    "#### Data loading/setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        label = self.labels[idx]\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "transformtrain = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transformtest = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transformtrain)\n",
    "test_data = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transformtest)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
{
   "cell_type": "markdown",
   "id": "86e8607c-d329-48de-aaca-6243dc98b401",
   "metadata": {},
   "source": [
    "#### Seed setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakeDropFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, training=True, p_drop=0.5, alpha_range=[-1, 1]):\n",
    "        if training:\n",
    "            gate = torch.cuda.FloatTensor([0]).bernoulli_(1 - p_drop)\n",
    "            ctx.save_for_backward(gate)\n",
    "            if gate.item() == 0:\n",
    "                alpha = torch.cuda.FloatTensor(x.size(0)).uniform_(*alpha_range)\n",
    "                alpha = alpha.view(alpha.size(0), 1, 1, 1).expand_as(x)\n",
    "                return alpha * x\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            return (1 - p_drop) * x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        gate = ctx.saved_tensors[0]\n",
    "        if gate.item() == 0:\n",
    "            beta = torch.cuda.FloatTensor(grad_output.size(0)).uniform_(0, 1)\n",
    "            beta = beta.view(beta.size(0), 1, 1, 1).expand_as(grad_output)\n",
    "            beta = Variable(beta)\n",
    "            return beta * grad_output, None, None, None\n",
    "        else:\n",
    "            return grad_output, None, None, None\n",
    "\n",
    "class ShakeDrop(nn.Module):\n",
    "    def __init__(self, p_drop=0.5, alpha_range=[-1, 1]):\n",
    "        super(ShakeDrop, self).__init__()\n",
    "        self.p_drop = p_drop\n",
    "        self.alpha_range = alpha_range\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ShakeDropFunction.apply(x, self.training, self.p_drop, self.alpha_range)\n",
    "\n",
    "# ShakePyramidNet 구현\n",
    "class ShakeBasicBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1, p_shakedrop=1.0):\n",
    "        super(ShakeBasicBlock, self).__init__()\n",
    "        self.downsampled = stride == 2\n",
    "        self.branch = self._make_branch(in_ch, out_ch, stride=stride)\n",
    "        self.shortcut = None if not self.downsampled else nn.AvgPool2d(2)\n",
    "        self.shake_drop = ShakeDrop(p_shakedrop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.branch(x)\n",
    "        h = self.shake_drop(h)\n",
    "        h0 = x if not self.downsampled else self.shortcut(x)\n",
    "        pad_zero = Variable(torch.zeros(h0.size(0), h.size(1) - h0.size(1), h0.size(2), h0.size(3)).float()).cuda()\n",
    "        h0 = torch.cat([h0, pad_zero], dim=1)\n",
    "        return h + h0\n",
    "\n",
    "    def _make_branch(self, in_ch, out_ch, stride=1):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(in_ch),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch))\n",
    "\n",
    "class ShakePyramidNet(nn.Module):\n",
    "    def __init__(self, depth=110, alpha=270, label=100):\n",
    "        super(ShakePyramidNet, self).__init__()\n",
    "        in_ch = 16\n",
    "        n_units = (depth - 2) // 6\n",
    "        in_chs = [in_ch] + [in_ch + math.ceil((alpha / (3 * n_units)) * (i + 1)) for i in range(3 * n_units)]\n",
    "        block = ShakeBasicBlock\n",
    "\n",
    "        self.in_chs, self.u_idx = in_chs, 0\n",
    "        self.ps_shakedrop = [1 - (1.0 - (0.5 / (3 * n_units)) * (i + 1)) for i in range(3 * n_units)]\n",
    "\n",
    "        self.c_in = nn.Conv2d(3, in_chs[0], 3, padding=1)\n",
    "        self.bn_in = nn.BatchNorm2d(in_chs[0])\n",
    "        self.layer1 = self._make_layer(n_units, block, 1)\n",
    "        self.layer2 = self._make_layer(n_units, block, 2)\n",
    "        self.layer3 = self._make_layer(n_units, block, 2)\n",
    "        self.bn_out = nn.BatchNorm2d(in_chs[-1])\n",
    "        self.fc_out = nn.Linear(in_chs[-1], label)\n",
    "\n",
    "        # 파라미터 초기화\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.bn_in(self.c_in(x))\n",
    "        h = self.layer1(h)\n",
    "        h = self.layer2(h)\n",
    "        h = self.layer3(h)\n",
    "        h = F.relu(self.bn_out(h))\n",
    "        h = F.avg_pool2d(h, 8)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        h = self.fc_out(h)\n",
    "        return h\n",
    "\n",
    "    def _make_layer(self, n_units, block, stride=1):\n",
    "        layers = []\n",
    "        for i in range(int(n_units)):\n",
    "            layers.append(block(self.in_chs[self.u_idx], self.in_chs[self.u_idx+1], stride, self.ps_shakedrop[self.u_idx]))\n",
    "            self.u_idx, stride = self.u_idx + 1, 1\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_topk(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def super_class_accuracy(output, target):\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "    pred_superclass = torch.tensor([get_superclass(p.item()) for p in predicted], dtype=torch.long)\n",
    "    target_superclass = torch.tensor([get_superclass(t.item()) for t in target], dtype=torch.long)\n",
    "\n",
    "    correct = (pred_superclass == target_superclass).sum().item()\n",
    "    total = target.size(0)\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "superclass_mapping = {\n",
    "    0: [4, 30, 55, 72, 95],   # aquatic mammals\n",
    "    1: [1, 32, 67, 73, 91],   # fish\n",
    "    2: [54, 62, 70, 82, 92],  # flowers\n",
    "    3: [9, 10, 16, 28, 61],   # food containers\n",
    "    4: [0, 51, 53, 57, 83],   # fruit and vegetables\n",
    "    5: [22, 39, 40, 86, 87],  # household electrical devices\n",
    "    6: [5, 20, 25, 84, 94],   # household furniture\n",
    "    7: [6, 7, 14, 18, 24],    # insects\n",
    "    8: [3, 42, 43, 88, 97],   # large carnivores\n",
    "    9: [12, 17, 37, 68, 76],  # large man-made outdoor things\n",
    "    10: [23, 33, 49, 60, 71], # large natural outdoor scenes\n",
    "    11: [15, 19, 21, 31, 38], # large omnivores and herbivores\n",
    "    12: [34, 63, 64, 66, 75], # medium-sized mammals\n",
    "    13: [26, 45, 77, 79, 99], # non-insect invertebrates\n",
    "    14: [2, 11, 35, 46, 98],  # people\n",
    "    15: [27, 29, 44, 78, 93], # reptiles\n",
    "    16: [36, 50, 65, 74, 80], # small mammals\n",
    "    17: [47, 52, 56, 59, 96], # trees\n",
    "    18: [8, 13, 48, 58, 90],  # vehicles 1\n",
    "    19: [41, 69, 81, 85, 89], # vehicles 2\n",
    "}\n",
    "\n",
    "def get_superclass(label):\n",
    "    for super_class, classes in superclass_mapping.items():\n",
    "        if label in classes:\n",
    "            return super_class\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(x.size()[0]).to(x.device)\n",
    "    target_a = y\n",
    "    target_b = y[rand_index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "    return x, target_a, target_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, use_cutmix=False, use_mixup=False):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        if use_cutmix:\n",
    "            inputs, target_a, target_b, lam = cutmix_data(inputs, labels)\n",
    "            outputs = model(inputs)\n",
    "            loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "        elif use_mixup:\n",
    "            inputs, target_a, target_b, lam = mixup_data(inputs, labels)\n",
    "            outputs = model(inputs)\n",
    "            loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    top1_correct = 0\n",
    "    top5_correct = 0\n",
    "    super_class_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            top1_acc, top5_acc = accuracy_topk(outputs, labels, topk=(1, 5))\n",
    "            top1_correct += (top1_acc.item() * inputs.size(0)) / 100\n",
    "            top5_correct += (top5_acc.item() * inputs.size(0)) / 100\n",
    "            super_class_correct += super_class_accuracy(outputs, labels) * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    top1_accuracy = 100.0 * top1_correct / total\n",
    "    top5_accuracy = 100.0 * top5_correct / total\n",
    "    super_class_accuracy_final = super_class_correct / total\n",
    "\n",
    "    return epoch_loss, top1_accuracy, top5_accuracy, super_class_accuracy_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, criterion, optimizer, scheduler, num_epochs, train_loader, test_loader, device):\n",
    "    best_combined_accuracy = 270\n",
    "    best_model_path = None \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device, use_cutmix=True)\n",
    "        val_loss, val_top1_acc, val_top5_acc, val_super_class_acc = evaluate(model, test_loader, criterion, device)\n",
    "        combined_accuracy = val_top1_acc + val_top5_acc + val_super_class_acc\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print(f'Test Loss: {val_loss:.4f}, Top-1 Accuracy: {val_top1_acc:.2f}%, Top-5 Accuracy: {val_top5_acc:.2f}%, Super-Class Accuracy: {val_super_class_acc:.2f}%')\n",
    "\n",
    "        scheduler.step(val_top1_acc)\n",
    "\n",
    "        if combined_accuracy > best_combined_accuracy:\n",
    "            best_combined_accuracy = combined_accuracy\n",
    "\n",
    "            if best_model_path and os.path.exists(best_model_path):\n",
    "                os.remove(best_model_path)\n",
    "\n",
    "            best_model_path = f\"pyramidnet_best_model_epoch_{epoch + 1}.pth\"\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"New best model found at Epoch {epoch + 1} with combined accuracy: {combined_accuracy:.2f}. Model saved.\")\n",
    "\n",
    "\n",
    "config = {\n",
    "    'epoch': 200,\n",
    "    'lr': 0.1,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum': 0.9,\n",
    "    \"nesterov\": True,\n",
    "    'patience': 10,\n",
    "    'factor': 0.1,   \n",
    "    'min_lr': 1e-6   \n",
    "}\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ShakePyramidNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    momentum=config['momentum'],\n",
    "    nesterov=config[\"nesterov\"]\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=config['factor'],\n",
    "    patience=config['patience'],\n",
    "    min_lr=config['min_lr']\n",
    ")\n",
    "\n",
    "\n",
    "train_and_evaluate(model, criterion, optimizer, scheduler, config['epoch'], train_loader, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haptic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
