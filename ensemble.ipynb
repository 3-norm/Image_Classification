{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb9a0f8-808a-44d3-8841-dbc131249d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import math\n",
    "from torchvision import transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8607c-d329-48de-aaca-6243dc98b401",
   "metadata": {},
   "source": [
    "#### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b55c654b-cada-4436-b5ce-97af8bbb735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transformtest = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transformtest)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff328b4-fbdf-4be5-b237-c6c60ddc4a42",
   "metadata": {},
   "source": [
    "### WideResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2fee4-75e7-4eab-8023-937e7d70ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return torch.relu(out)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, widen_factor=10, num_classes=100):\n",
    "        super(WideResNet, self).__init__()\n",
    "        self.in_planes = 16 * widen_factor \n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes) \n",
    "\n",
    "        self.layer1 = self._make_layer(block, 16 * widen_factor, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32 * widen_factor, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64 * widen_factor, num_blocks[2], stride=2)\n",
    "\n",
    "        self.linear = nn.Linear(64 * widen_factor, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x))) \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = torch.mean(out, dim=[2, 3]) \n",
    "        return self.linear(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff903e-82b8-4660-9b45-4f8703fac109",
   "metadata": {},
   "source": [
    "### PyramidNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7cdd6ab-b4a0-40e8-8b41-ddb1bfda28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakeDropFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, training=True, p_drop=0.5, alpha_range=[-1, 1]):\n",
    "        if training:\n",
    "            gate = torch.cuda.FloatTensor([0]).bernoulli_(1 - p_drop)\n",
    "            ctx.save_for_backward(gate)\n",
    "            if gate.item() == 0:\n",
    "                alpha = torch.cuda.FloatTensor(x.size(0)).uniform_(*alpha_range)\n",
    "                alpha = alpha.view(alpha.size(0), 1, 1, 1).expand_as(x)\n",
    "                return alpha * x\n",
    "            else:\n",
    "                return x\n",
    "        else:\n",
    "            return (1 - p_drop) * x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        gate = ctx.saved_tensors[0]\n",
    "        if gate.item() == 0:\n",
    "            beta = torch.cuda.FloatTensor(grad_output.size(0)).uniform_(0, 1)\n",
    "            beta = beta.view(beta.size(0), 1, 1, 1).expand_as(grad_output)\n",
    "            beta = Variable(beta)\n",
    "            return beta * grad_output, None, None, None\n",
    "        else:\n",
    "            return grad_output, None, None, None\n",
    "\n",
    "class ShakeDrop(nn.Module):\n",
    "    def __init__(self, p_drop=0.5, alpha_range=[-1, 1]):\n",
    "        super(ShakeDrop, self).__init__()\n",
    "        self.p_drop = p_drop\n",
    "        self.alpha_range = alpha_range\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ShakeDropFunction.apply(x, self.training, self.p_drop, self.alpha_range)\n",
    "\n",
    "\n",
    "class ShakeBasicBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1, p_shakedrop=1.0):\n",
    "        super(ShakeBasicBlock, self).__init__()\n",
    "        self.downsampled = stride == 2\n",
    "        self.branch = self._make_branch(in_ch, out_ch, stride=stride)\n",
    "        self.shortcut = None if not self.downsampled else nn.AvgPool2d(2)\n",
    "        self.shake_drop = ShakeDrop(p_shakedrop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.branch(x)\n",
    "        h = self.shake_drop(h)\n",
    "        h0 = x if not self.downsampled else self.shortcut(x)\n",
    "        pad_zero = Variable(torch.zeros(h0.size(0), h.size(1) - h0.size(1), h0.size(2), h0.size(3)).float()).cuda()\n",
    "        h0 = torch.cat([h0, pad_zero], dim=1)\n",
    "        return h + h0\n",
    "\n",
    "    def _make_branch(self, in_ch, out_ch, stride=1):\n",
    "        return nn.Sequential(\n",
    "            nn.BatchNorm2d(in_ch),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch))\n",
    "\n",
    "class ShakePyramidNet(nn.Module):\n",
    "    def __init__(self, depth=110, alpha=270, label=100):\n",
    "        super(ShakePyramidNet, self).__init__()\n",
    "        in_ch = 16\n",
    "        n_units = (depth - 2) // 6\n",
    "        in_chs = [in_ch] + [in_ch + math.ceil((alpha / (3 * n_units)) * (i + 1)) for i in range(3 * n_units)]\n",
    "        block = ShakeBasicBlock\n",
    "\n",
    "        self.in_chs, self.u_idx = in_chs, 0\n",
    "        self.ps_shakedrop = [1 - (1.0 - (0.5 / (3 * n_units)) * (i + 1)) for i in range(3 * n_units)]\n",
    "\n",
    "        self.c_in = nn.Conv2d(3, in_chs[0], 3, padding=1)\n",
    "        self.bn_in = nn.BatchNorm2d(in_chs[0])\n",
    "        self.layer1 = self._make_layer(n_units, block, 1)\n",
    "        self.layer2 = self._make_layer(n_units, block, 2)\n",
    "        self.layer3 = self._make_layer(n_units, block, 2)\n",
    "        self.bn_out = nn.BatchNorm2d(in_chs[-1])\n",
    "        self.fc_out = nn.Linear(in_chs[-1], label)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.bn_in(self.c_in(x))\n",
    "        h = self.layer1(h)\n",
    "        h = self.layer2(h)\n",
    "        h = self.layer3(h)\n",
    "        h = F.relu(self.bn_out(h))\n",
    "        h = F.avg_pool2d(h, 8)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        h = self.fc_out(h)\n",
    "        return h\n",
    "\n",
    "    def _make_layer(self, n_units, block, stride=1):\n",
    "        layers = []\n",
    "        for i in range(int(n_units)):\n",
    "            layers.append(block(self.in_chs[self.u_idx], self.in_chs[self.u_idx+1], stride, self.ps_shakedrop[self.u_idx]))\n",
    "            self.u_idx, stride = self.u_idx + 1, 1\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860712df-fb76-4cef-ad3e-f9a672f5cd31",
   "metadata": {},
   "source": [
    "### accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d846984-c30e-4e5a-b48d-f16574d9a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_topk(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size)) \n",
    "    return res\n",
    "\n",
    "\n",
    "superclass_mapping = {\n",
    "    0: [4, 30, 55, 72, 95],   # aquatic mammals\n",
    "    1: [1, 32, 67, 73, 91],   # fish\n",
    "    2: [54, 62, 70, 82, 92],  # flowers\n",
    "    3: [9, 10, 16, 28, 61],   # food containers\n",
    "    4: [0, 51, 53, 57, 83],   # fruit and vegetables\n",
    "    5: [22, 39, 40, 86, 87],  # household electrical devices\n",
    "    6: [5, 20, 25, 84, 94],   # household furniture\n",
    "    7: [6, 7, 14, 18, 24],    # insects\n",
    "    8: [3, 42, 43, 88, 97],   # large carnivores\n",
    "    9: [12, 17, 37, 68, 76],  # large man-made outdoor things\n",
    "    10: [23, 33, 49, 60, 71], # large natural outdoor scenes\n",
    "    11: [15, 19, 21, 31, 38], # large omnivores and herbivores\n",
    "    12: [34, 63, 64, 66, 75], # medium-sized mammals\n",
    "    13: [26, 45, 77, 79, 99], # non-insect invertebrates\n",
    "    14: [2, 11, 35, 46, 98],  # people\n",
    "    15: [27, 29, 44, 78, 93], # reptiles\n",
    "    16: [36, 50, 65, 74, 80], # small mammals\n",
    "    17: [47, 52, 56, 59, 96], # trees\n",
    "    18: [8, 13, 48, 58, 90],  # vehicles 1\n",
    "    19: [41, 69, 81, 85, 89], # vehicles 2\n",
    "}\n",
    "\n",
    "def get_superclass(label):\n",
    "    for super_class, classes in superclass_mapping.items():\n",
    "        if label in classes:\n",
    "            return super_class\n",
    "    return None\n",
    "\n",
    "\n",
    "def super_class_accuracy(output, target):\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "    pred_superclass = torch.tensor([get_superclass(p.item()) for p in predicted], dtype=torch.long)\n",
    "    target_superclass = torch.tensor([get_superclass(t.item()) for t in target], dtype=torch.long)\n",
    "\n",
    "    correct = (pred_superclass == target_superclass).sum().item()\n",
    "    total = target.size(0)\n",
    "\n",
    "    accuracy = 100.0 * (correct / total)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363dcfae-b6c5-48ed-bebf-996e214c7ed2",
   "metadata": {},
   "source": [
    "## Ensemble (soft voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d3826-76f8-483d-9314-1d0f37525ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "\n",
    "model1_path = \"your_path/model1_best_model.pth\"\n",
    "model2_path = \"your_path/model2_best_model.pth\"\n",
    "\n",
    "model1 = WideResNet(BasicBlock, [4, 4, 4], widen_factor=10).to(device)\n",
    "model2 = ShakePyramidNet().to(device)\n",
    "\n",
    "\n",
    "model1.load_state_dict(torch.load(model1_path))\n",
    "model2.load_state_dict(torch.load(model2_path))\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "def evaluate_ensemble(model1, model2, dataloader, criterion, device):\n",
    "    total_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    correct_superclass = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs1 = model1(inputs)\n",
    "            outputs2 = model2(inputs)\n",
    "            \n",
    "            outputs_ensemble = F.softmax((0.4 * outputs1 + 0.6 * outputs2) / 2, dim=1)\n",
    "\n",
    "            loss = criterion(outputs_ensemble, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Top-1, Top-5 \n",
    "            top1_acc, top5_acc = accuracy_topk(outputs_ensemble, targets, topk=(1, 5))\n",
    "            correct_top1 += top1_acc.item() * inputs.size(0)\n",
    "            correct_top5 += top5_acc.item() * inputs.size(0)\n",
    "\n",
    "            # super class accuracy\n",
    "            superclass_acc = super_class_accuracy(outputs_ensemble, targets)\n",
    "            correct_superclass += superclass_acc * inputs.size(0)\n",
    "\n",
    "            total += targets.size(0)\n",
    "\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    top1_accuracy = correct_top1 / total\n",
    "    top5_accuracy = correct_top5 / total\n",
    "    superclass_accuracy = correct_superclass / total\n",
    "\n",
    "    return avg_loss, top1_accuracy, top5_accuracy, superclass_accuracy\n",
    "\n",
    "\n",
    "test_loss, test_top1_acc, test_top5_acc, test_superclass_acc = evaluate_ensemble(model1, model2, test_loader, criterion, device)\n",
    "\n",
    "print(f'Test Top-1 Accuracy: {test_top1_acc:.2f}%')\n",
    "print(f'Test Top-5 Accuracy: {test_top5_acc:.2f}%')\n",
    "print(f'Test Super-Class Accuracy: {test_superclass_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haptic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
