{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import wandb\n",
    "import random\n",
    "import math\n",
    "\n",
    "import tarfile\n",
    "import pickle\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8607c-d329-48de-aaca-6243dc98b401",
   "metadata": {},
   "source": [
    "#### Seed setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seed(327)"
   ]
  },
 {
   "cell_type": "markdown",
   "id": "86e8607c-d329-48de-aaca-6243dc98b401",
   "metadata": {},
   "source": [
    "#### Train/Test data setting"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        label = self.labels[idx]\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "transformtrain = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "transformtest = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transformtrain)\n",
    "test_data = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transformtest)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },

 {
   "cell_type": "markdown",
   "id": "86e8607c-d329-48de-aaca-6243dc98b401",
   "metadata": {},
   "source": [
    "#### WideResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WideResNet28x10 모델 직접 정의\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return torch.relu(out)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, widen_factor=10, num_classes=100):\n",
    "        super(WideResNet, self).__init__()\n",
    "        self.in_planes = 16 * widen_factor \n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes) \n",
    "\n",
    "        self.layer1 = self._make_layer(block, 16 * widen_factor, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32 * widen_factor, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64 * widen_factor, num_blocks[2], stride=2)\n",
    "\n",
    "        self.linear = nn.Linear(64 * widen_factor, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x))) \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = torch.mean(out, dim=[2, 3]) \n",
    "        return self.linear(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_topk(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def super_class_accuracy(output, target):\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "    pred_superclass = torch.tensor([get_superclass(p.item()) for p in predicted], dtype=torch.long)\n",
    "    target_superclass = torch.tensor([get_superclass(t.item()) for t in target], dtype=torch.long)\n",
    "\n",
    "    correct = (pred_superclass == target_superclass).sum().item()\n",
    "    total = target.size(0)\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "superclass_mapping = {\n",
    "    0: [4, 30, 55, 72, 95],   # aquatic mammals\n",
    "    1: [1, 32, 67, 73, 91],   # fish\n",
    "    2: [54, 62, 70, 82, 92],  # flowers\n",
    "    3: [9, 10, 16, 28, 61],   # food containers\n",
    "    4: [0, 51, 53, 57, 83],   # fruit and vegetables\n",
    "    5: [22, 39, 40, 86, 87],  # household electrical devices\n",
    "    6: [5, 20, 25, 84, 94],   # household furniture\n",
    "    7: [6, 7, 14, 18, 24],    # insects\n",
    "    8: [3, 42, 43, 88, 97],   # large carnivores\n",
    "    9: [12, 17, 37, 68, 76],  # large man-made outdoor things\n",
    "    10: [23, 33, 49, 60, 71], # large natural outdoor scenes\n",
    "    11: [15, 19, 21, 31, 38], # large omnivores and herbivores\n",
    "    12: [34, 63, 64, 66, 75], # medium-sized mammals\n",
    "    13: [26, 45, 77, 79, 99], # non-insect invertebrates\n",
    "    14: [2, 11, 35, 46, 98],  # people\n",
    "    15: [27, 29, 44, 78, 93], # reptiles\n",
    "    16: [36, 50, 65, 74, 80], # small mammals\n",
    "    17: [47, 52, 56, 59, 96], # trees\n",
    "    18: [8, 13, 48, 58, 90],  # vehicles 1\n",
    "    19: [41, 69, 81, 85, 89], # vehicles 2\n",
    "}\n",
    "\n",
    "def get_superclass(label):\n",
    "    for super_class, classes in superclass_mapping.items():\n",
    "        if label in classes:\n",
    "            return super_class\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(x.size()[0]).to(x.device)\n",
    "    target_a = y\n",
    "    target_b = y[rand_index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "    return x, target_a, target_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, use_cutmix=False, use_mixup=False):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        if use_cutmix:\n",
    "            inputs, target_a, target_b, lam = cutmix_data(inputs, labels)\n",
    "            outputs = model(inputs)\n",
    "            loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "        elif use_mixup:\n",
    "            inputs, target_a, target_b, lam = mixup_data(inputs, labels)\n",
    "            outputs = model(inputs)\n",
    "            loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    top1_correct = 0\n",
    "    top5_correct = 0\n",
    "    super_class_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            top1_acc, top5_acc = accuracy_topk(outputs, labels, topk=(1, 5))\n",
    "            top1_correct += (top1_acc.item() * inputs.size(0)) / 100\n",
    "            top5_correct += (top5_acc.item() * inputs.size(0)) / 100\n",
    "            super_class_correct += super_class_accuracy(outputs, labels) * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    top1_accuracy = 100.0 * top1_correct / total\n",
    "    top5_accuracy = 100.0 * top5_correct / total\n",
    "    super_class_accuracy_final = super_class_correct / total\n",
    "\n",
    "    return epoch_loss, top1_accuracy, top5_accuracy, super_class_accuracy_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, criterion, optimizer, scheduler, num_epochs, train_loader, test_loader, device):\n",
    "    best_combined_accuracy = 260\n",
    "    best_model_path = None \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device, use_cutmix=True)\n",
    "        val_loss, val_top1_acc, val_top5_acc, val_super_class_acc = evaluate(model, test_loader, criterion, device)\n",
    "        combined_accuracy = val_top1_acc + val_top5_acc + val_super_class_acc\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print(f'Test Loss: {val_loss:.4f}, Top-1 Accuracy: {val_top1_acc:.2f}%, Top-5 Accuracy: {val_top5_acc:.2f}%, Super-Class Accuracy: {val_super_class_acc:.2f}%')\n",
    "\n",
    "        scheduler.step(val_top1_acc)\n",
    "\n",
    "        if combined_accuracy > best_combined_accuracy:\n",
    "            best_combined_accuracy = combined_accuracy\n",
    "\n",
    "            if best_model_path and os.path.exists(best_model_path):\n",
    "                os.remove(best_model_path)\n",
    "\n",
    "            best_model_path = f\"wide-resnet_best_model_epoch_{epoch + 1}.pth\"\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"New best model found at Epoch {epoch + 1} with combined accuracy: {combined_accuracy:.2f}. Model saved.\")\n",
    "\n",
    "\n",
    "config = {\n",
    "    'epoch': 200,\n",
    "    'lr': 0.1,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum': 0.9,\n",
    "    'milestones':[60,120,160],\n",
    "    'gamma':0.2\n",
    "}\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = WideResNet(BasicBlock, [4, 4, 4], widen_factor=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=config['lr'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    momentum=config['momentum']\n",
    ")\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones = config['milestones'],\n",
    "    gamma = config['gamma']\n",
    ")\n",
    "\n",
    "\n",
    "train_and_evaluate(model, criterion, optimizer, scheduler, config['epoch'], train_loader, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haptic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
